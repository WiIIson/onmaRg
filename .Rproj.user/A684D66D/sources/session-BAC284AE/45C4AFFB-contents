# ===============
# Loading package
# ===============
library(tidyverse)    # Data cleaning functions
library(readxl)       # Loading data from Excel
library(httr)         # Read data from URL
library(sf)           # Spatial features package to read shape files
library(RColorBrewer) # Colour palettes for the map
library(leaflet)      # Street maps
library(shiny)        # Shiny dashboard

# ==============
# Set Parameters
# ==============

# I can probably delete all of this but i'll leave it in for now
student_file_name <- "C:/Users/willi/Documents/Professional Work/TCDSB-2022-OnMarg/Data/2021_StudentData_Scrub/SHP/2021_StudentData_Scrub.dbf"
DA_SHP_name <- "C:/Users/willi/Documents/Professional Work/TCDSB-2022-OnMarg/Data/Shapefiles/lda/lda_000b16a_e.shp"
school_file_name <- "C:/Users/willi/Documents/Professional Work/TCDSB-2022-OnMarg/Data/EPAN_Data/SHP/2022_TCDSB_Sites.shp"
superintendent_SHP_name <- "C:/Users/willi/Documents/Professional Work/TCDSB-2022-OnMarg/Data/EPAN_Data/SHP/Superintendent_Area.shp"
attendence_SHP_name <- "C:/Users/willi/Documents/Professional Work/TCDSB-2022-OnMarg/Data/EPAN_Data/SHP/Fixed_Attendance_Boundaries.shp"

CRS_to_use <- st_crs("+init=EPSG:2962") # NAD83 UTM Zone 17N
main_city <- "Toronto"



# ==============================================================================
# Loading ON-Marg data
# ==============================================================================

# Gets OnMarg shape data for a given year
# Prints an error message if the given year is not available
shapeMarg <- function(year, level) {
  year <- toString(year)
  CRS_to_use <- st_crs("+init=EPSG:2962") # NAD83 UTM Zone 17N
  geoLevels <- c("DAUID", "CTUID", "CSDUID", "CCSUID", "CDUID", "CMAUID", "PHUUID", "LHINUID", "LHIN_SRUID")
  if (!level %in% geoLevels) {
    stop(paste0("Level ", level, " is not recognized"))
  }
  switch(year,
         # url       <- URL for the marginalization data
         # page      <- Worksheet in the file (CHANGE THIS)
         # format    <- Format of the file
         # stats_url <- URL for the shapefile
         "2001"={
           #url <- "http://www.ontariohealthprofiles.ca/onmarg/userguide_data/ON-Marg_2001_updated_May_2012.xls"
           #page <- "da_01"
           #format <- ".xls"
           #stat_url <- "https://www12.statcan.gc.ca/census-recensement/2011/geo/bound-limit/files-fichiers/gda_000b01a_e.zip"
           stop("This year has not yet been implemented")
         },
         "2006"={
           #url <- "http://www.ontariohealthprofiles.ca/onmarg/userguide_data/ON-Marg_2006_updated_May_2012.xls"
           #page <- "da_06"
           #format <- ".xls"
           #stat_url <- "https://www12.statcan.gc.ca/census-recensement/2011/geo/bound-limit/files-fichiers/gda_000a06a_e.zip"
           stop("This year has not yet been implemented")
         },
         "2011"={
           url <- "https://www.publichealthontario.ca/-/media/Data-Files/index-on-marg-2011.xlsx?la=en&sc_lang=en&hash=88EFEB83D1A1DFC5A90517AE2E71C855"
           #page <- "DA_2011"
           format <- ".xlsx"
           stat_url <- "https://www12.statcan.gc.ca/census-recensement/2011/geo/bound-limit/files-fichiers/gda_000a11a_e.zip"
         },
         "2016"={
           url <- "https://www.publichealthontario.ca/-/media/Data-Files/index-on-marg.xls?sc_lang=en"
           #page <- "DA_2016"
           format <- ".xls"
           stat_url <- "https://www12.statcan.gc.ca/census-recensement/2011/geo/bound-limit/files-fichiers/2016/lda_000b16a_e.zip"
         },
         {
           # Breaks if an invalid ON-Marg year is entered
           stop("There is no record for year " + year)
         }
  )
  
  if (level == "DAUID") {
    page <- paste0("DA_", year)
  }
  else {
    page <- paste0(year, "_", level)
  }
  
  #print(page)
  
  # Gets the name of a file from its URL
  getFileName <- function(url, extension) {
    str_extract(url, "\\/([a-z]|[0-9]|_)+.zip") %>%
      substring(2) %>%
      str_replace(".zip", ".shp")
  }
  
  # Extracts all geographic files from zip
  extractFromZip <- function(url) {
    tempDir <- tempdir()
    tempFile <- tempfile()
    
    filename <- getFileName(url)
    
    download.file(url, tempFile, quiet=TRUE, mode="wb")
    
    extensions <- c(".shp", ".dbf", ".prj", ".shx")
    for (extension in extensions) {
      filename <- str_extract(url, "\\/([a-z]|[0-9]|_)+.zip") %>%
        substring(2) %>%
        str_replace(".zip", extension)
      
      unzip(tempFile, filename, exdir=tempDir)
    }
    
    filepath <- paste0(tempDir, "/", filename)
    
    return(st_read(filepath))
  }
  
  # Loads the worksheet into a temporary file (tf)
  GET(url, write_disk(tf <- tempfile(fileext=format)))
  
  # Dataframe containing marginalization data
  df1 <- read_excel(tf, sheet=page)
  colnames(df1) <- toupper(colnames(df1))
  
  # Dataframe containing shape data
  df2 <- extractFromZip(stat_url) %>%
    st_transform(CRS_to_use) #%>%
  
  # Summarize the dataframe if not selecting DAUID
  if (!level == "DAUID") {
    df2 <- df2 %>%
      group_by_at(level) %>%
      summarize(geometry=st_union(geometry))
  }
  
  #print(colnames(df1))
  #print(colnames(df2))
  
  # Merges geographic location with ON-Marg values and returns the data frame
  shape_marg <- merge(df2, df1, by=level)
  
  return(shape_marg)
}

# Loads ON-Marg data for a given year
OnMarg_16_DA <- shapeMarg(2016, "DAUID")
OnMarg_16_CMA <- shapeMarg(2016, "CMAUID")
OnMarg_16_CSD <- shapeMarg(2016, "CSDUID")

ggplot() +
  geom_sf(data=OnMarg_16_DA) +
  coord_sf()

ggplot() +
  geom_sf(data=OnMarg_16_CMA) +
  coord_sf()

ggplot() +
  geom_sf(data=OnMarg_16_CSD) +
  coord_sf()




# ==============================================================================
# Loading DAs and Attaching OnMarg
# ==============================================================================

# Loading the shape file
DA_SHP <- st_read(DA_SHP_name, stringsAsFactors=FALSE) %>%
  st_transform(CRS_to_use) %>%
  select(-CSDNAME, -CSDTYPE, -CTUID, -CTNAME)

# Merge with ON-Marg data and create index column
DA_OnMarg <- merge(DA_SHP, OnMarg_16, by="DAUID") %>%
  mutate(index=(Dependency_q_DA16 + Deprivation_q_DA16 + Ethniccon_q_DA16 + Instability_q_DA16)/4)

# ==============================================================================
# Loading Student Data and DAs
# ==============================================================================

# Get student data
student_data <- foreign::read.dbf(student_file_name, as.is=TRUE) %>%
  filter(X > 0)

# Geocoding student location
student_geo <- st_as_sf(student_data,
                        coords=c("X", "Y"),
                        crs="+init=EPSG:26917") %>%
  mutate(SchoolCode = as.numeric(SchoolCode)) %>%
  st_transform(CRS_to_use)

# Find the DAs that students are in
student_geo <- st_join(student_geo, left=FALSE, DA_OnMarg)

#write.csv(select(student_geo, -OEN, -StudentID), "student_geo.csv", row.names=FALSE) # Student file used for Power BI

student_DA <- student_geo$DAUID %>%
  unique()

# ==============================================================================
# Filtering DAs for Student Locations
# ==============================================================================

# Filter DA_OnMarg by the main city and DAs students are in
DA_OnMarg <- filter(DA_OnMarg, CCSNAME == main_city | DAUID %in% student_DA) %>%
  mutate(isMainCity = CSDNAME == main_city)

# Re-project data for leaflet
toronto_DA <- st_transform(DA_OnMarg, 4326)







# ==============================================================================
# Load School Locations
# ==============================================================================

school_SHP <- st_read(school_file_name, stringsAsFactors=FALSE) %>%
  st_transform(4326) %>%
  mutate(x=st_coordinates(geometry)[,1], y=st_coordinates(geometry)[,2])

#ggplot() +
#  geom_sf(data=toronto_DA) +
#  geom_sf(data=school_SHP) +
#  coord_sf()


# colour = student average index
# size = number of students


total_Dep5Percent <- mean(student_geo$Deprivation_q_DA16 == 5)

# Table of school codes and grades
#school_types <- school_SHP %>%
#  mutate(
#    secondary=(Grade_Rang=="9-S12"),
#    SchoolCode=Scode
#  ) %>%
#  select(SchoolCode, secondary) %>%
#  st_drop_geometry()

# Table of student data by school
school_table <- student_geo %>%
  group_by(SchoolCode, Name) %>%
  summarise(
    Total=n(),
    RelativeTotal=n()/nrow(student_geo) * length(unique(student_geo$SchoolCode)) * 10,
    Dep1=sum(Deprivation_q_DA16==1),
    Dep2=sum(Deprivation_q_DA16==2),
    Dep3=sum(Deprivation_q_DA16==3),
    Dep4=sum(Deprivation_q_DA16==4),
    Dep5=sum(Deprivation_q_DA16==5),
    Dep5Percent=round(Dep5/Total,2),
    Disproportionality=round(Dep5Percent/total_Dep5Percent,4),
    CDI=mean(index)
  ) %>%
  arrange(Dep5Percent) %>%
  #  merge(school_types, by="SchoolCode") %>%
  st_drop_geometry()

School_SHP_table <- school_SHP %>%
  mutate(SchoolCode=Scode) %>%
  merge(school_table, by="SchoolCode")


#write.csv(select(school_table, -RelativeTotal), "school_table.csv", row.names=FALSE) # Write school table as csv

ggplot(school_table, aes(x=CDI)) +
  geom_density()






superintendent_SHP <- st_read(superintendent_SHP_name, stringsAsFactors=FALSE) %>%
  st_transform(4326)

leaflet() %>%
  addTiles() %>%
  addPolygons(
    data=superintendent_SHP,
    opacity=1,
    color="Black",
    fill=FALSE
  ) %>%
  addCircleMarkers(
    data=School_SHP_table,
    lng=~x,
    lat=~y,
    radius=0.1,
    color="Black",
    opacity=0.6
  )






attendence_SHP <- st_read(attendence_SHP_name, stringsAsFactors=FALSE) %>%
  filter(FDELK_Name != "Greater Toronto Area") %>%
  mutate(SchoolCode = as.numeric(TCDSB_Code)) %>%
  merge(school_types, by="SchoolCode", left=TRUE) %>%
  st_transform(4326)

type_color <- function(type) {
  if (type) {
    return("Blue")
  }
  else {
    return("Red")
  }
}

leaflet() %>%
  addTiles() %>%
  addPolygons(
    data=attendence_SHP,
    popup=attendence_SHP$FDELK_Name,
    color=type_color(attendence_SHP$secondary)
  )






# Define colour palette
assign_colour <- function(nums, level) {
  colours <- colorRampPalette(brewer.pal(5,"RdYlGn"))(17)
  pal <- vector()
  for (num in nums) {
    if (is.na(num) || (level != 0 && level != num)) {
      pal <- append(pal, "#EBEBEB")
    }
    else {
      pal <- append(pal, colours[18 - (num * 4 - 3)])
    }
  }
  return(pal)
}


generate_site_markers <- function() {
  site_markers <- leaflet(School_SHP_table) %>%
    addTiles() %>%
    addCircleMarkers(
      lng=~x,
      lat=~y,
      radius=~RelativeTotal,
      color=assign_colour(floor(School_SHP_table$Dep5Percent / 20) + 1, 0)
      #clusterOptions = markerClusterOptions()
    )
  
  return(site_markers)
}

generate_site_markers()



# Generate map from column of OnMarg dimensions
generateMap <- function(col, level) {
  p_popup <- paste0("<strong>Level: </strong>", col)  # Set popup message
  
  marg_map <- leaflet(toronto_DA) %>%
    addTiles() %>%
    addPolygons(
      stroke=FALSE,
      color=assign_colour(col,level),
      fillOpacity=0.8,
      smoothFactor=0.5,
      popup=p_popup,
      layerId=col
    ) %>%
    addPolygons(
      data=superintendent_SHP,
      opacity=1,
      color="Black",
      fill=FALSE
    ) %>%
    addCircleMarkers(
      data=School_SHP_table,
      lng=~x,
      lat=~y,
      radius=0.1,
      color="Black",
      opacity=0.6
    )
  
  return(marg_map)
}

# Test map
generateMap(toronto_DA$Deprivation_q_DA16, 0)  



# Makes a marker map on top of the DA map
leaflet() %>%
  addTiles() %>%
  addPolygons(
    data=toronto_DA,
    stroke=FALSE,
    color=assign_colour(toronto_DA$Deprivation_q_DA16, 0),
    fillOpacity=0.8,
    smoothFactor=0.5,
    popup=paste0("<strong>Level: </strong>", toronto_DA$Deprivation_q_DA16),
    layerId=toronto_DA$Deprivation_q_DA16
  ) %>%
  addCircleMarkers(
    data=School_SHP_table,
    lng=~x,
    lat=~y,
    radius=~RelativeTotal,
    color=assign_colour(floor(School_SHP_table$Dep5Percent / 20) + 1, 0)
    #clusterOptions = markerClusterOptions()
  )